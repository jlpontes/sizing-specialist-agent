import os
import logging
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain.agents import tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents.format_scratchpad.openai_tools import (
    format_to_openai_tool_messages,
)
from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser
from langchain.agents import AgentExecutor
from pydantic import BaseModel, Field
from typing import List
from langchain_core.messages import HumanMessage, AIMessage

# Importar nossas fun√ß√µes l√≥gicas
import logic_sizing

# --- CONFIGURA√á√ÉO INICIAL ---
load_dotenv()

# MELHORIA: Configurar logging para capturar erros detalhados
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Carregar os dados uma vez no in√≠cio
print("Carregando dados de performance...")
df, df_alvo = logic_sizing.data_preparation('rperf_tabela.csv')
print("Dados carregados. O agente est√° pronto.")
print("="*50)

# --- DEFINI√á√ÉO DA ESTRUTURA DE DADOS DAS FERRAMENTAS ---
class Servidor(BaseModel):
    """Descreve um √∫nico tipo de servidor no invent√°rio do cliente."""
    modelo: str = Field(description="O nome exato do modelo do servidor.")
    servidores: int = Field(description="A quantidade de servidores deste modelo.")
    cores: int = Field(description="O n√∫mero de cores ativos por servidor.")
    utilizacao: float = Field(description="O pico de utiliza√ß√£o a ser considerado para este servidor, em decimal (ex: 0.8 para 80%).")

class CalculoSizingInput(BaseModel):
    """Input para a ferramenta de c√°lculo de sizing."""
    inventario_cliente: List[Servidor] = Field(description="Uma lista de todos os servidores no ambiente atual do cliente.")
    taxa_anual_crescimento: float = Field(default=0.0, description="A taxa de crescimento anual em porcentagem (ex: 20 para 20%).")
    anos_projecao: int = Field(default=0, description="O n√∫mero de anos para a proje√ß√£o de crescimento.")

# --- CRIA√á√ÉO DA FERRAMENTA (TOOL) ---
@tool(args_schema=CalculoSizingInput)
def calcular_cenarios_de_sizing(inventario_cliente: List[Servidor], taxa_anual_crescimento: float, anos_projecao: int) -> str:
    """
    Use esta ferramenta APENAS quando tiver coletado TODAS as informa√ß√µes sobre os servidores
    atuais do cliente (modelo, quantidade, cores, utiliza√ß√£o) e os requisitos de crescimento.
    Ela calcula e retorna os melhores cen√°rios de consolida√ß√£o para um novo hardware.
    """
    # Converter a lista de Pydantic models para o formato que nossa fun√ß√£o espera (dicion√°rio)
    inventario_dict = {
        s.modelo: {"servidores": s.servidores, "cores": s.cores, "utilizacao": s.utilizacao}
        for s in inventario_cliente
    }
    
    # --- MELHORIA 3: TRATAMENTO DE ERROS ---
    try:
        resultados = logic_sizing.calcular_e_ranquear_cenarios_completos(
            df=df,
            df_alvo=df_alvo,
            inventario_cliente=inventario_dict,
            taxa_anual_crescimento=taxa_anual_crescimento,
            anos_projecao=anos_projecao
        )

        if not resultados:
            return "N√£o foram encontrados cen√°rios v√°lidos com os dados fornecidos."

        # --- MELHORIA: FORMATA√á√ÉO COM MARKDOWN ---
        resposta_formatada = "Aqui est√£o os melhores cen√°rios de sizing encontrados: üèÜ\n"
        for i, c in enumerate(resultados):
            util_percent = c['utilizacao_cores'] * 100
            resposta_formatada += (
                f"\n**{i+1}. Modelo:** `{c['modelo_unico']}`\n"
                f"   - **Configura√ß√£o:** {c['servidores']} servidor(es) com {c['cores_por_servidor']} cores ativos cada.\n"
                f"   - **Novo rPerf Total:** {c['rperf_novo']:.2f} (`+{c['excedente_rperf']:.2f}` de folga)\n"
                f"   - **Utiliza√ß√£o de Cores:** {util_percent:.1f}%\n"
                "--------------------\n"
            )
        return resposta_formatada

    except Exception as e:
        # Loga o erro completo para debug interno
        logging.error(f"Erro ao executar a ferramenta de sizing: {e}", exc_info=True)
        # Retorna uma mensagem amig√°vel para o usu√°rio
        return "Ocorreu um erro interno ao processar sua solicita√ß√£o. Verifique se os nomes dos modelos de servidor est√£o corretos e tente novamente."

# --- CRIA√á√ÉO DO AGENTE ---

# --- MELHORIA 5: CARREGAMENTO EXPL√çCITO DA API KEY ---
# Garante que a chave do .env seja usada corretamente
api_key = os.getenv("GROQ_API_KEY")
if not api_key:
    raise ValueError("A vari√°vel de ambiente GROQ_API_KEY n√£o foi encontrada...")

llm = ChatGroq(model="llama3-70b-8192", temperature=0, api_key=api_key)

tools = [calcular_cenarios_de_sizing]
llm_with_tools = llm.bind_tools(tools)

# --- SYSTEM PROMPT MAIS ROBUSTO ---
# Mais diretivo para evitar loops e conversas fora de escopo
system_prompt = """Voc√™ √© um assistente especialista em sizing de servidores IBM Power. Sua √∫nica fun√ß√£o √© ajudar os usu√°rios a calcular cen√°rios de consolida√ß√£o de hardware.

Siga estas regras estritamente:
1.  Para sauda√ß√µes simples e conversas informais (como 'Ol√°', 'Oi', 'Tudo bem?'), responda de forma educada, se apresente brevemente e pergunte como pode ajudar com o sizing e explique como ele deve usa-lo guiando passo-a-passo. N√£o tente usar ferramentas para isso.
2.  Seu objetivo principal √© coletar todas as informa√ß√µes para usar a ferramenta `calcular_cenarios_de_sizing`.
3.  As informa√ß√µes necess√°rias s√£o: uma lista de servidores atuais (modelo, quantidade, cores, utiliza√ß√£o) e, opcionalmente, uma proje√ß√£o de crescimento (taxa e anos).
4.  Guie o usu√°rio passo a passo. Pe√ßa uma informa√ß√£o de cada vez at√© ter tudo que precisa.
5.  NUNCA chame a ferramenta `calcular_cenarios_de_sizing` antes de ter pelo menos um servidor no invent√°rio. Se o usu√°rio pedir para calcular sem fornecer dados, explique que voc√™ precisa das informa√ß√µes primeiro.
6.  N√£o responda a perguntas que n√£o sejam sobre sizing de servidores IBM Power. Se o usu√°rio perguntar sobre outro assunto, gentilmente diga que voc√™ s√≥ pode ajudar com sizing.
7.  N√£o invente modelos de servidor ou qualquer outra informa√ß√£o.
"""


prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    MessagesPlaceholder(variable_name="chat_history"),
    ("user", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

agent = (
    {
        "input": lambda x: x["input"],
        "agent_scratchpad": lambda x: format_to_openai_tool_messages(x["intermediate_steps"]),
        "chat_history": lambda x: x["chat_history"],
    }
    | prompt
    | llm_with_tools
    | OpenAIToolsAgentOutputParser()
)

agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# --- MELHORIA 4: ORGANIZA√á√ÉO DO C√ìDIGO EM FUN√á√ïES ---
def run_chat():
    """Fun√ß√£o principal que executa o loop de chat com o usu√°rio."""
    # --- MELHORIA 2: GERENCIAMENTO DE HIST√ìRICO MANUAL ---
    chat_history = []
    
    while True:
        user_input = input("Voc√™: ")
        if user_input.lower() in ["exit", "sair"]:
            break
        
        # Adiciona a mensagem do usu√°rio ao hist√≥rico
        chat_history.append(HumanMessage(content=user_input))
        
        result = agent_executor.invoke({
            "input": user_input,
            "chat_history": chat_history
        })
        
        # Adiciona a resposta do agente ao hist√≥rico
        chat_history.append(AIMessage(content=result["output"]))
        
        print("\nAgente:", result["output"])
        print("\n" + "="*50 + "\n")

if __name__ == "__main__":
    run_chat()